
# ChatSter

A **general-purpose chatbot** built using [LangGraph](https://github.com/langchain-ai/langgraph), designed for multi-threaded conversations with persistent storage, an interactive front-end, and support for multiple LLMs.

---

## âœ¨ Features

* **Multi-threaded Conversations**

  * Create, reset, and switch across multiple chat sessions.
  * Persistent conversation history stored with **SQLite**.

* **Interactive Streamlit Frontend**

  * Real-time streaming of chatbot responses.
  * Clean, intuitive UI for managing multiple conversations.

* **Support for tool calling**
  * Real time search results using google search integration.
  * MySQL database interaction support and with safe query checking.
  * Multiple other tools implemented

* **LLM Flexibility**

  * Plug-and-play integration with different **LLMs**, including custom fine-tuned models.
  * Ongoing benchmarking with **LangSmith** for performance tracking.

* **Scalable & Extensible**

  * Designed with modularity in mind to support future **multimodal integration** (text + images + more).

---

## ğŸ“¸ Demo

### Chat Interface

![Chat Interface Demo](assets/chat_interface.png)

### Multi-Thread Conversation Management

![Multi-thread Demo](assets/multithread_demo.gif)

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ langgraph_backend.py     # Backend: LangGraph pipeline, thread management, persistence
â”œâ”€â”€ frontend_multithread.py  # Frontend: Streamlit app with multithread chat support
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ assets/                  # (Optional) screenshots and GIFs for README
â””â”€â”€ README.md                # Project documentation
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/langgraph-chatbot.git
cd langgraph-chatbot
```

### 2. Install Dependencies

It is recommended to use a virtual environment:

```bash
pip install -r requirements.txt
```

### 3. Set Environment Variables

Create a `.env` file in the project root and add your API keys (e.g., OpenAI):

```env
OPENAI_API_KEY=your_openai_key_here
LANGSMITH_API_KEY=your_langsmith_key_here   # optional, for benchmarking
```

### 4. Run the Backend

The backend manages LangGraph workflows and persistent conversation storage.

```bash
python langgraph_backend.py
```

### 5. Run the Frontend

Launch the Streamlit interface:

```bash
streamlit run frontend_multithread.py
```

---

## ğŸ–¥ï¸ Usage

1. Open the Streamlit app in your browser (default: `http://localhost:8501`).
2. Start a new conversation thread or continue from previous ones.
3. Switch between multiple active threads.
4. Enjoy real-time chatbot responses powered by LangGraph.

---

## ğŸ”® Roadmap

* âœ… Multi-threaded conversation management
* âœ… S3QLite persistence
* âœ… Streamlit real-time streaming
* ğŸ”„ LLM benchmarking with LangSmith
* ğŸ”® Multimodal integration (text + images, documents)
* ğŸ”® Deployment on cloud (Docker + Kubernetes)

